---
output: pdf_document
---


Dear John Drake,

We are pleased to present a proposal for an article discussing the potential use of deep Reinforcement Learning in theoretical and applied ecological conservation for the Methods section of Ecology Letters.

Advances in both available data and computing power have begun to open the door to a greater role for machine learning (ML) in addressing some of our planet's most pressing environmental problems, such as the growing frequency and intensity of wildfire, over-exploited fisheries, declining biodiversity, and zoonotic pandemics. 
Will such approaches really help us tackle a changing planet? 
The reliance of dominant machine learning approaches on existing data can make them a valuable tool for automating well-understood steps in an analysis, but may also make them a poor tool to predict the long-term dynamics of a no-analogue future and the non-representative distribution of available ecological data. 
Supervised Learning methods have proven very successful in tasks such as image classification, with the promise of being able to automate species identification from cameras, acoustic sensors or satellite images. 
Unsupervised learning methods hold out a more ambitious promise of identifying features or making predictions without first requiring a large training set labeled data. 
The least attention has been paid to what may be the most promising member of the ML triumvirate: Reinforcement Learning (RL). 
RL trains a software agent to maximize some objective -- notable examples include navigation in autonomous robots or Google's AlphaZero. 
RL requires agents to make decisions in dynamic and uncertain environments that plan ahead and change the state of the board. Also unlike other approaches, such agents are typically trained, not on mountains of data alone, but on simulations.

We describe how this creates a bridge between the rich, mechanistic or process based models of our field and the power of ML to discover creative solutions to complex decision problems. 
Rather than seeking to displace process-based models of the past century with opaque machines, we illustrate how we can use such mechanistic models to drive realistic simulations which we can then train leading RL algorithms to manage. 
We demonstrate this approach using examples from fisheries management, ecosystem tipping points, and wildfire spread. 
All though our examples are primarily a proof-of-principle, they serve to illuminate both the promise, as well as potential pitfalls 
Those pitfalls are not only technical, but include issues of ethics and power, particularly if the algorithms or data are proprietary. 
We conclude with a discussion of how an open, transparent and reproducible approach can help mitigate some concerns, while also offering a more effective interface between teams of researchers from both ecological and computer sciences.

We include an extensive appendix with carefully annotated code which should allow readers to both reproduce and extend this analysis.
We further include implementations of three fully featured python modules following current leading standards, which would allow engineers and computer scientists already working in RL to test their agents against both solved and unsolved problems in conservation management.
We believe this piece would provide an effective introduction to the concepts and practices of RL which would allow ecologists to apply, extend, and critically critique such methods.


