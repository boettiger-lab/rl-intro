---
output: pdf_document
---


Dear John Drake,

We are pleased to present a proposal for an article discussing the potential use of deep Reinforcement Learning in theoretical and applied ecological conservation for the Methods section of Ecology Letters.

Advances in both available data and computing power have begun to open the door to a greater role for machine learning (ML) in addressing some of our planet's most pressing environmental problems, such as the growing frequency and intensity of wildfire, over-exploited fisheries, declining biodiversity, and zoonotic pandemics. 
Will such approaches really help us tackle a changing planet? 
Machine learning is traditionally divided into three categories: supervised learning, unsupervised learning and reinforcement learning.
Of these three branches, reinforcement learning has garnered the least amount of attention from ecologists despite it potentially being the most impactful for ecological conservation.
The goal of RL is to train a software agent to maximize some objective in a dynamic environment -- notable examples include navigation in autonomous robots or Google's AlphaZero. 
An advantage of RL is that unlike other branches of ML, RL can rely entirely on simulators to achieve optimal performance.

Rather than seeking to displace process-based models of the past century with opaque machines, we illustrate how we can use such mechanistic models to drive realistic simulations which we can then train leading RL algorithms to manage. 
We demonstrate this approach using examples from fisheries management, ecosystem tipping points, and wildfire spread. 
Although our examples are primarily a proof-of-principle, they serve to illuminate both the promise as well as potential pitfalls. 
Those pitfalls are not only technical, but include issues of ethics and power, particularly if the algorithms or data are proprietary. 
We conclude with a discussion of how an open, transparent and reproducible approach can help mitigate some concerns, while also offering a more effective interface between teams of researchers from both ecological and computer sciences.

We include an extensive appendix with carefully annotated code which should allow readers to both reproduce and extend this analysis.
We further include implementations of three fully featured python modules following current leading standards, which would allow engineers and computer scientists already working in RL to test their agents against both solved and unsolved problems in conservation management.
We believe this piece would provide an effective introduction to the concepts and practices of RL which would allow ecologists to apply, extend, and critique such methods.


