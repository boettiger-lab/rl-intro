
@article{brockman2016,
	title = {{OpenAI} {Gym}},
	url = {http://arxiv.org/abs/1606.01540},
	abstract = {OpenAI Gym is a toolkit for reinforcement learning research. It includes a growing collection of benchmark problems that expose a common interface, and a website where people can share their results and compare the performance of algorithms. This whitepaper discusses the components of OpenAI Gym and the design decisions that went into the software.},
	urldate = {2021-04-29},
	journal = {arXiv:1606.01540 [cs]},
	author = {Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
	month = jun,
	year = {2016},
	note = {arXiv: 1606.01540},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:/home/cboettig/Zotero/storage/AIS2GFG4/Brockman et al. - 2016 - OpenAI Gym.pdf:application/pdf;arXiv.org Snapshot:/home/cboettig/Zotero/storage/62NTAUKT/1606.html:text/html}
}

@article{openai_costs,
	title = {Measuring the {Algorithmic} {Efficiency} of {Neural} {Networks}},
	url = {http://arxiv.org/abs/2005.04305},
	abstract = {Three factors drive the advance of AI: algorithmic innovation, data, and the amount of compute available for training. Algorithmic progress has traditionally been more difficult to quantify than compute and data. In this work, we argue that algorithmic progress has an aspect that is both straightforward to measure and interesting: reductions over time in the compute needed to reach past capabilities. We show that the number of floating-point operations required to train a classifier to AlexNet-level performance on ImageNet has decreased by a factor of 44x between 2012 and 2019. This corresponds to algorithmic efficiency doubling every 16 months over a period of 7 years. By contrast, Moore's Law would only have yielded an 11x cost improvement. We observe that hardware and algorithmic efficiency gains multiply and can be on a similar scale over meaningful horizons, which suggests that a good model of AI progress should integrate measures from both.},
	urldate = {2021-05-11},
	journal = {arXiv:2005.04305 [cs, stat]},
	author = {Hernandez, Danny and Brown, Tom B.},
	month = may,
	year = {2020},
	note = {arXiv: 2005.04305},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: 20 pages, 5 figures},
	file = {arXiv Fulltext PDF:/home/cboettig/Zotero/storage/UGAGPLRA/Hernandez and Brown - 2020 - Measuring the Algorithmic Efficiency of Neural Net.pdf:application/pdf;arXiv.org Snapshot:/home/cboettig/Zotero/storage/7DBDL3IU/2005.html:text/html}
}

@article{biodiversity,
 title={Defaunation in the Anthropocene},
  author={Dirzo, Rodolfo and Young, Hillary S and Galetti, Mauro and Ceballos, Gerardo and Isaac, Nick JB and Collen, Ben},
   journal={science},
   volume={345},
   number={6195},
   pages={401--406},
   year={2014},
   publisher={American Association for the Advancement of Science}
 }

@article{sac,
	title = {Soft {Actor}-{Critic}: {Off}-{Policy} {Maximum} {Entropy} {Deep} {Reinforcement} {Learning} with a {Stochastic} {Actor}},
	shorttitle = {Soft {Actor}-{Critic}},
	url = {http://arxiv.org/abs/1801.01290},
	abstract = {Model-free deep reinforcement learning (RL) algorithms have been demonstrated on a range of challenging decision making and control tasks. However, these methods typically suffer from two major challenges: very high sample complexity and brittle convergence properties, which necessitate meticulous hyperparameter tuning. Both of these challenges severely limit the applicability of such methods to complex, real-world domains. In this paper, we propose soft actor-critic, an off-policy actor-critic deep RL algorithm based on the maximum entropy reinforcement learning framework. In this framework, the actor aims to maximize expected reward while also maximizing entropy. That is, to succeed at the task while acting as randomly as possible. Prior deep RL methods based on this framework have been formulated as Q-learning methods. By combining off-policy updates with a stable stochastic actor-critic formulation, our method achieves state-of-the-art performance on a range of continuous control benchmark tasks, outperforming prior on-policy and off-policy methods. Furthermore, we demonstrate that, in contrast to other off-policy algorithms, our approach is very stable, achieving very similar performance across different random seeds.},
	urldate = {2021-05-05},
	journal = {arXiv:1801.01290 [cs, stat]},
	author = {Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
	month = aug,
	year = {2018},
	note = {arXiv: 1801.01290},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: ICML 2018 Videos: sites.google.com/view/soft-actor-critic Code: github.com/haarnoja/sac},
	file = {arXiv Fulltext PDF:/home/cboettig/Zotero/storage/EMT3HQTG/Haarnoja et al. - 2018 - Soft Actor-Critic Off-Policy Maximum Entropy Deep.pdf:application/pdf;arXiv.org Snapshot:/home/cboettig/Zotero/storage/TRBDQEN5/1801.html:text/html}
}

@article{TD3,
	title = {Addressing {Function} {Approximation} {Error} in {Actor}-{Critic} {Methods}},
	url = {http://arxiv.org/abs/1802.09477},
	abstract = {In value-based reinforcement learning methods such as deep Q-learning, function approximation errors are known to lead to overestimated value estimates and suboptimal policies. We show that this problem persists in an actor-critic setting and propose novel mechanisms to minimize its effects on both the actor and the critic. Our algorithm builds on Double Q-learning, by taking the minimum value between a pair of critics to limit overestimation. We draw the connection between target networks and overestimation bias, and suggest delaying policy updates to reduce per-update error and further improve performance. We evaluate our method on the suite of OpenAI gym tasks, outperforming the state of the art in every environment tested.},
	urldate = {2021-05-05},
	journal = {arXiv:1802.09477 [cs, stat]},
	author = {Fujimoto, Scott and van Hoof, Herke and Meger, David},
	month = oct,
	year = {2018},
	note = {arXiv: 1802.09477},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: Accepted at ICML 2018},
	file = {arXiv Fulltext PDF:/home/cboettig/Zotero/storage/7QWN2IXY/Fujimoto et al. - 2018 - Addressing Function Approximation Error in Actor-C.pdf:application/pdf;arXiv.org Snapshot:/home/cboettig/Zotero/storage/8QGUZGAP/1802.html:text/html}
}

@article{her,
	title = {Hindsight {Experience} {Replay}},
	url = {http://arxiv.org/abs/1707.01495},
	abstract = {Dealing with sparse rewards is one of the biggest challenges in Reinforcement Learning (RL). We present a novel technique called Hindsight Experience Replay which allows sample-efficient learning from rewards which are sparse and binary and therefore avoid the need for complicated reward engineering. It can be combined with an arbitrary off-policy RL algorithm and may be seen as a form of implicit curriculum. We demonstrate our approach on the task of manipulating objects with a robotic arm. In particular, we run experiments on three different tasks: pushing, sliding, and pick-and-place, in each case using only binary rewards indicating whether or not the task is completed. Our ablation studies show that Hindsight Experience Replay is a crucial ingredient which makes training possible in these challenging environments. We show that our policies trained on a physics simulation can be deployed on a physical robot and successfully complete the task.},
	urldate = {2021-05-05},
	journal = {arXiv:1707.01495 [cs]},
	author = {Andrychowicz, Marcin and Wolski, Filip and Ray, Alex and Schneider, Jonas and Fong, Rachel and Welinder, Peter and McGrew, Bob and Tobin, Josh and Abbeel, Pieter and Zaremba, Wojciech},
	month = feb,
	year = {2018},
	note = {arXiv: 1707.01495},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Computer Science - Robotics},
	file = {arXiv Fulltext PDF:/home/cboettig/Zotero/storage/FH3QSE54/Andrychowicz et al. - 2018 - Hindsight Experience Replay.pdf:application/pdf;arXiv.org Snapshot:/home/cboettig/Zotero/storage/DH3PBZBY/1707.html:text/html}
}

@article{DQN,
	title = {Human-level control through deep reinforcement learning},
	volume = {518},
	issn = {0028-0836, 1476-4687},
	url = {http://www.nature.com/articles/nature14236},
	doi = {10.1038/nature14236},
	language = {en},
	number = {7540},
	urldate = {2021-05-05},
	journal = {Nature},
	author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
	month = feb,
	year = {2015},
	pages = {529--533}
}

@article{dqn_arxiv,
	title = {Playing {Atari} with {Deep} {Reinforcement} {Learning}},
	url = {http://arxiv.org/abs/1312.5602},
	abstract = {We present the first deep learning model to successfully learn control policies directly from high-dimensional sensory input using reinforcement learning. The model is a convolutional neural network, trained with a variant of Q-learning, whose input is raw pixels and whose output is a value function estimating future rewards. We apply our method to seven Atari 2600 games from the Arcade Learning Environment, with no adjustment of the architecture or learning algorithm. We find that it outperforms all previous approaches on six of the games and surpasses a human expert on three of them.},
	urldate = {2021-05-05},
	journal = {arXiv:1312.5602 [cs]},
	author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
	month = dec,
	year = {2013},
	note = {arXiv: 1312.5602},
	keywords = {Computer Science - Machine Learning},
	annote = {Comment: NIPS Deep Learning Workshop 2013},
	file = {arXiv Fulltext PDF:/home/cboettig/Zotero/storage/9759TK3T/Mnih et al. - 2013 - Playing Atari with Deep Reinforcement Learning.pdf:application/pdf;arXiv.org Snapshot:/home/cboettig/Zotero/storage/927GQNHK/1312.html:text/html}
}

@article{ddpg,
	title = {Continuous control with deep reinforcement learning},
	url = {http://arxiv.org/abs/1509.02971},
	abstract = {We adapt the ideas underlying the success of Deep Q-Learning to the continuous action domain. We present an actor-critic, model-free algorithm based on the deterministic policy gradient that can operate over continuous action spaces. Using the same learning algorithm, network architecture and hyper-parameters, our algorithm robustly solves more than 20 simulated physics tasks, including classic problems such as cartpole swing-up, dexterous manipulation, legged locomotion and car driving. Our algorithm is able to find policies whose performance is competitive with those found by a planning algorithm with full access to the dynamics of the domain and its derivatives. We further demonstrate that for many of the tasks the algorithm can learn policies end-to-end: directly from raw pixel inputs.},
	urldate = {2021-05-05},
	journal = {arXiv:1509.02971 [cs, stat]},
	author = {Lillicrap, Timothy P. and Hunt, Jonathan J. and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
	month = jul,
	year = {2019},
	note = {arXiv: 1509.02971},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: 10 pages + supplementary},
	file = {arXiv Fulltext PDF:/home/cboettig/Zotero/storage/AJNAETMB/Lillicrap et al. - 2019 - Continuous control with deep reinforcement learnin.pdf:application/pdf;arXiv.org Snapshot:/home/cboettig/Zotero/storage/SL6FXX4V/1509.html:text/html}
}

@article{A2C,
	title = {Asynchronous {Methods} for {Deep} {Reinforcement} {Learning}},
	url = {http://arxiv.org/abs/1602.01783},
	abstract = {We propose a conceptually simple and lightweight framework for deep reinforcement learning that uses asynchronous gradient descent for optimization of deep neural network controllers. We present asynchronous variants of four standard reinforcement learning algorithms and show that parallel actor-learners have a stabilizing effect on training allowing all four methods to successfully train neural network controllers. The best performing method, an asynchronous variant of actor-critic, surpasses the current state-of-the-art on the Atari domain while training for half the time on a single multi-core CPU instead of a GPU. Furthermore, we show that asynchronous actor-critic succeeds on a wide variety of continuous motor control problems as well as on a new task of navigating random 3D mazes using a visual input.},
	urldate = {2021-05-05},
	journal = {arXiv:1602.01783 [cs]},
	author = {Mnih, Volodymyr and Badia, Adrià Puigdomènech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy P. and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
	month = jun,
	year = {2016},
	note = {arXiv: 1602.01783},
	keywords = {Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:/home/cboettig/Zotero/storage/PHJJPHS2/Mnih et al. - 2016 - Asynchronous Methods for Deep Reinforcement Learni.pdf:application/pdf;arXiv.org Snapshot:/home/cboettig/Zotero/storage/YDTHBLKH/1602.html:text/html}
}


@misc{sb3,
  author = {Raffin, Antonin and Hill, Ashley and Ernestus, Maximilian and Gleave, Adam and Kanervisto, Anssi and Dormann, Noah},
  title = {Stable Baselines3},
  year = {2019},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/DLR-RM/stable-baselines3}},
}

@misc{tf-agents,
  title = {{TF-Agents}: A library for Reinforcement Learning in TensorFlow},
  author = {Sergio Guadarrama and Anoop Korattikara and Oscar Ramirez and
     Pablo Castro and Ethan Holly and Sam Fishman and Ke Wang and
     Ekaterina Gonina and Neal Wu and Efi Kokiopoulou and Luciano Sbaiz and
     Jamie Smith and Gábor Bartók and Jesse Berent and Chris Harris and
     Vincent Vanhoucke and Eugene Brevdo},
  howpublished = {\url{https://github.com/tensorflow/agents}},
  url = "https://github.com/tensorflow/agents",
  year = 2018,
  note = "[Online; accessed May 2021]"
}

@inproceedings{kour2014real,
  title={Real-time segmentation of on-line handwritten arabic script},
  author={Kour, George and Saabne, Raid},
  booktitle={Frontiers in Handwriting Recognition (ICFHR), 2014 14th International Conference on},
  pages={417--422},
  year={2014},
  organization={IEEE}
}

@inproceedings{kour2014fast,
  title={Fast classification of handwritten on-line Arabic characters},
  author={Kour, George and Saabne, Raid},
  booktitle={Soft Computing and Pattern Recognition (SoCPaR), 2014 6th International Conference of},
  pages={312--318},
  year={2014},
  organization={IEEE}
}

@article{hadash2018estimate,
  title={Estimate and Replace: A Novel Approach to Integrating Deep Neural Networks with Existing Applications},
  author={Hadash, Guy and Kermany, Einat and Carmeli, Boaz and Lavi, Ofer and Kour, George and Jacovi, Alon},
  journal={arXiv preprint arXiv:1804.09028},
  year={2018}
}


@article{alphazero,
	title = {A general reinforcement learning algorithm that masters chess, shogi, and {Go} through self-play},
	volume = {362},
	issn = {0036-8075, 1095-9203},
	url = {https://www.sciencemag.org/lookup/doi/10.1126/science.aar6404},
	doi = {10.1126/science.aar6404},
	abstract = {The game of chess is the longest-studied domain in the history of artificial intelligence. The strongest programs are based on a combination of sophisticated search techniques, domain-specific adaptations, and handcrafted evaluation functions that have been refined by human experts over several decades. By contrast, the AlphaGo Zero program recently achieved superhuman performance in the game of Go by reinforcement learning from self-play. In this paper, we generalize this approach into a single AlphaZero algorithm that can achieve superhuman performance in many challenging games. Starting from random play and given no domain knowledge except the game rules, AlphaZero convincingly defeated a world champion program in the games of chess and shogi (Japanese chess), as well as Go.},
	language = {en},
	number = {6419},
	urldate = {2021-05-07},
	journal = {Science},
	author = {Silver, David and Hubert, Thomas and Schrittwieser, Julian and Antonoglou, Ioannis and Lai, Matthew and Guez, Arthur and Lanctot, Marc and Sifre, Laurent and Kumaran, Dharshan and Graepel, Thore and Lillicrap, Timothy and Simonyan, Karen and Hassabis, Demis},
	month = dec,
	year = {2018},
	pages = {1140--1144},
	file = {Full Text:/home/cboettig/Zotero/storage/CMYED7HD/Silver et al. - 2018 - A general reinforcement learning algorithm that ma.pdf:application/pdf}
}


@article{Pong2020,
	title = {Temporal {Difference} {Models}: {Model}-{Free} {Deep} {RL} for {Model}-{Based} {Control}},
	shorttitle = {Temporal {Difference} {Models}},
	url = {http://arxiv.org/abs/1802.09081},
	abstract = {Model-free reinforcement learning (RL) is a powerful, general tool for learning complex behaviors. However, its sample efficiency is often impractically large for solving challenging real-world problems, even with off-policy algorithms such as Q-learning. A limiting factor in classic model-free RL is that the learning signal consists only of scalar rewards, ignoring much of the rich information contained in state transition tuples. Model-based RL uses this information, by training a predictive model, but often does not achieve the same asymptotic performance as model-free RL due to model bias. We introduce temporal difference models (TDMs), a family of goal-conditioned value functions that can be trained with model-free learning and used for model-based control. TDMs combine the benefits of model-free and model-based RL: they leverage the rich information in state transitions to learn very efficiently, while still attaining asymptotic performance that exceeds that of direct model-based RL methods. Our experimental results show that, on a range of continuous control tasks, TDMs provide a substantial improvement in efficiency compared to state-of-the-art model-based and model-free methods.},
	urldate = {2021-05-25},
	journal = {arXiv:1802.09081 [cs]},
	author = {Pong, Vitchyr and Gu, Shixiang and Dalal, Murtaza and Levine, Sergey},
	month = feb,
	year = {2020},
	note = {arXiv: 1802.09081},
	keywords = {Computer Science - Machine Learning},
	annote = {Comment: Appeared in ICLR 2018; typos corrected},
	file = {arXiv Fulltext PDF:/home/cboettig/Zotero/storage/AU5CTSZT/Pong et al. - 2020 - Temporal Difference Models Model-Free Deep RL for.pdf:application/pdf;arXiv.org Snapshot:/home/cboettig/Zotero/storage/ZJD3I26K/1802.html:text/html}
}


@article{alphaGoZero,
	title = {Mastering the game of {Go} without human knowledge},
	volume = {550},
	issn = {0028-0836, 1476-4687},
	url = {http://www.nature.com/articles/nature24270},
	doi = {10.1038/nature24270},
	language = {en},
	number = {7676},
	urldate = {2021-05-07},
	journal = {Nature},
	author = {Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and Chen, Yutian and Lillicrap, Timothy and Hui, Fan and Sifre, Laurent and van den Driessche, George and Graepel, Thore and Hassabis, Demis},
	month = oct,
	year = {2017},
	pages = {354--359},
	file = {Submitted Version:/home/cboettig/Zotero/storage/S7M2HI28/Silver et al. - 2017 - Mastering the game of Go without human knowledge.pdf:application/pdf}
}


@article{alphaGo2016,
	title = {Mastering the game of {Go} with deep neural networks and tree search},
	volume = {529},
	issn = {0028-0836, 1476-4687},
	url = {http://www.nature.com/articles/nature16961},
	doi = {10.1038/nature16961},
	language = {en},
	number = {7587},
	urldate = {2021-05-07},
	journal = {Nature},
	author = {Silver, David and Huang, Aja and Maddison, Chris J. and Guez, Arthur and Sifre, Laurent and van den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and Dieleman, Sander and Grewe, Dominik and Nham, John and Kalchbrenner, Nal and Sutskever, Ilya and Lillicrap, Timothy and Leach, Madeleine and Kavukcuoglu, Koray and Graepel, Thore and Hassabis, Demis},
	month = jan,
	year = {2016},
	pages = {484--489}
}


@article{covid,
	title = {Ecology and economics for pandemic prevention},
	volume = {369},
	issn = {0036-8075},
	url = {https://science.sciencemag.org/content/369/6502/379},
	doi = {10.1126/science.abc3189},
	number = {6502},
	journal = {Science},
	author = {Dobson, Andrew P. and Pimm, Stuart L. and Hannah, Lee and Kaufman, Les and Ahumada, Jorge A. and Ando, Amy W. and Bernstein, Aaron and Busch, Jonah and Daszak, Peter and Engelmann, Jens and Kinnaird, Margaret F. and Li, Binbin V. and Loch-Temzelides, Ted and Lovejoy, Thomas and Nowak, Katarzyna and Roehrdanz, Patrick R. and Vale, Mariana M.},
	year = {2020},
	pages = {379--381}
}

@article{fire_2,
	title = {Reform forest fire management},
	volume = {349},
	issn = {0036-8075, 1095-9203},
	url = {https://www.sciencemag.org/lookup/doi/10.1126/science.aab2356},
	doi = {10.1126/science.aab2356},
	language = {en},
	number = {6254},
	urldate = {2021-04-16},
	journal = {Science},
	author = {North, M. P. and Stephens, S. L. and Collins, B. M. and Agee, J. K. and Aplet, G. and Franklin, J. F. and Fule, P. Z.},
	month = sep,
	year = {2015},
	pages = {1280--1281}
}

@article{wildfire,
	title = {Learning to coexist with wildfire},
	volume = {515},
	issn = {0028-0836, 1476-4687},
	url = {http://www.nature.com/articles/nature13946},
	doi = {10.1038/nature13946},
	language = {en},
	number = {7525},
	urldate = {2021-04-16},
	journal = {Nature},
	author = {Moritz, Max A. and Batllori, Enric and Bradstock, Ross A. and Gill, A. Malcolm and Handmer, John and Hessburg, Paul F. and Leonard, Justin and McCaffrey, Sarah and Odion, Dennis C. and Schoennagel, Tania and Syphard, Alexandra D.},
	month = nov,
	year = {2014},
	pages = {58--66}
}


@article{biodiversity_oceans,
	title = {Protecting the global ocean for biodiversity, food and climate},
	volume = {592},
	issn = {0028-0836, 1476-4687},
	url = {http://www.nature.com/articles/s41586-021-03371-z},
	doi = {10.1038/s41586-021-03371-z},
	language = {en},
	number = {7854},
	urldate = {2021-04-16},
	journal = {Nature},
	author = {Sala, Enric and Mayorga, Juan and Bradley, Darcy and Cabral, Reniel B. and Atwood, Trisha B. and Auber, Arnaud and Cheung, William and Costello, Christopher and Ferretti, Francesco and Friedlander, Alan M. and Gaines, Steven D. and Garilao, Cristina and Goodell, Whitney and Halpern, Benjamin S. and Hinson, Audra and Kaschner, Kristin and Kesner-Reyes, Kathleen and Leprieur, Fabien and McGowan, Jennifer and Morgan, Lance E. and Mouillot, David and Palacios-Abrantes, Juliano and Possingham, Hugh P. and Rechberger, Kristin D. and Worm, Boris and Lubchenco, Jane},
	month = apr,
	year = {2021},
	pages = {397--402}
}


@article{fishwatch,
	title = {Ending hide and seek at sea},
	volume = {351},
	issn = {0036-8075, 1095-9203},
	url = {https://www.sciencemag.org/lookup/doi/10.1126/science.aad5686},
	doi = {10.1126/science.aad5686},
	language = {en},
	number = {6278},
	urldate = {2021-04-17},
	journal = {Science},
	author = {McCauley, Douglas J. and Woods, Paul and Sullivan, Brian and Bergman, Bjorn and Jablonicky, Caroline and Roan, Aaron and Hirshfield, Michael and Boerder, Kristina and Worm, Boris},
	month = mar,
	year = {2016},
	pages = {1148--1150}
}


@article{forestwatch,
	title = {High-{Resolution} {Global} {Maps} of 21st-{Century} {Forest} {Cover} {Change}},
	volume = {342},
	url = {http://science.sciencemag.org/content/342/6160/850.abstract},
	doi = {10.1126/science.1244693},
	abstract = {Forests worldwide are in a state of flux, with accelerating losses in some regions and gains in others. Hansen et al. (p. 850) examined global Landsat data at a 30-meter spatial resolution to characterize forest extent, loss, and gain from 2000 to 2012. Globally, 2.3 million square kilometers of forest were lost during the 12-year study period and 0.8 million square kilometers of new forest were gained. The tropics exhibited both the greatest losses and the greatest gains (through regrowth and plantation), with losses outstripping gains. Quantification of global forest change has been lacking despite the recognized importance of forest ecosystem services. In this study, Earth observation satellite data were used to map global forest loss (2.3 million square kilometers) and gain (0.8 million square kilometers) from 2000 to 2012 at a spatial resolution of 30 meters. The tropics were the only climate domain to exhibit a trend, with forest loss increasing by 2101 square kilometers per year. Brazil’s well-documented reduction in deforestation was offset by increasing forest loss in Indonesia, Malaysia, Paraguay, Bolivia, Zambia, Angola, and elsewhere. Intensive forestry practiced within subtropical forests resulted in the highest rates of forest change globally. Boreal forest loss due largely to fire and forestry was second to that in the tropics in absolute and proportional terms. These results depict a globally consistent and locally relevant record of forest change.},
	number = {6160},
	journal = {Science},
	author = {Hansen, M. C. and Potapov, P. V. and Moore, R. and Hancher, M. and Turubanova, S. A. and Tyukavina, A. and Thau, D. and Stehman, S. V. and Goetz, S. J. and Loveland, T. R. and Kommareddy, A. and Egorov, A. and Chini, L. and Justice, C. O. and Townshend, J. R. G.},
	month = nov,
	year = {2013},
	pages = {850}
}


@article{Joppa2017,
	title = {The case for technology investments in the environment},
	volume = {552},
	issn = {0028-0836, 1476-4687},
	url = {http://www.nature.com/articles/d41586-017-08675-7},
	doi = {10.1038/d41586-017-08675-7},
	language = {en},
	number = {7685},
	urldate = {2021-04-17},
	journal = {Nature},
	author = {Joppa, Lucas N.},
	month = dec,
	year = {2017},
	pages = {325--328},
	file = {Full Text:/home/cboettig/Zotero/storage/WYG4P7SM/Joppa - 2017 - The case for technology investments in the environ.pdf:application/pdf}
}



@article{noise-phenomena,
author = {Boettiger, Carl},
doi = {10.1111/ele.13085},
issn = {1461023X},
journal = {Ecology Letters},
title = {{From noise to knowledge: how randomness generates novel phenomena and reveals information}},
year = {2018}
}


@article{Nature2013,
author = {Boettiger, Carl and Hastings, Alan},
doi = {10.1038/493157a},
issn = {0028-0836},
journal = {Nature},
month = {jan},
number = {7431},
pages = {157--158},
title = {{Tipping points: From patterns to predictions}},
volume = {493},
year = {2013}
}


@article{EcoApps2016,
author = {Boettiger, Carl and Bode, Michael and Sanchirico, James N. and LaRiviere, Jacob and Hastings, Alan and Armsworth, Paul R.},
doi = {10.1890/15-0236},
issn = {10510761},
journal = {Ecological Applications},
month = {apr},
number = {3},
pages = {808--817},
title = {{Optimal management of a stochastically varying population when policy adjustment is costly}},
volume = {26},
year = {2016}
}

@article{nonparametric,
author = {Boettiger, Carl and Mangel, Marc and Munch, S.},
doi = {10.1098/rspb.2014.1631},
issn = {0962-8452},
journal = {Proceedings of the Royal Society B: Biological Sciences},
keywords = {ecology,theoretical biology},
month = {jan},
number = {1801},
pages = {20141631--20141631},
pmid = {25567644},
title = {{Avoiding tipping points in fisheries management through Gaussian process dynamic programming}},
volume = {282},
year = {2015}
}


@article{pomdp-ram,
	title = {Rebuilding global fisheries under uncertainty},
	issn = {0027-8424, 1091-6490},
	url = {http://www.pnas.org/lookup/doi/10.1073/pnas.1902657116},
	doi = {10.1073/pnas.1902657116},
	language = {en},
	urldate = {2019-08-01},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Memarzadeh, Milad and Britten, Gregory L. and Worm, Boris and Boettiger, Carl},
	month = jul,
	year = {2019},
	pages = {201902657}
}


@article{taxadb,
	title = {taxadb: {A} high‐performance local taxonomic database interface},
	volume = {11},
	copyright = {All rights reserved},
	issn = {2041-210X, 2041-210X},
	shorttitle = {taxadb},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.13440},
	doi = {10.1111/2041-210X.13440},
	language = {en},
	number = {9},
	urldate = {2021-04-17},
	journal = {Methods in Ecology and Evolution},
	author = {Norman, Kari E. A. and Chamberlain, Scott and Boettiger, Carl},
	editor = {Price, Samantha},
	month = sep,
	year = {2020},
	pages = {1153--1159},
	file = {Full Text:/home/cboettig/Zotero/storage/E9UEFQSS/Norman et al. - 2020 - taxadb A high‐performance local taxonomic databas.pdf:application/pdf}
}


@article{RJournal2018,
  author = {Carl Boettiger and Dirk Eddelbuettel},
  title = {{An Introduction to Rocker: Docker Containers for R}},
  year = {2017},
  journal = {{The R Journal}},
  url = {https://journal.r-project.org/archive/2017/RJ-2017-065/index.html},
  pages = {527--536},
  volume = {9},
  number = {2}
}

@article{Dietze2018,
author = {Dietze, Michael C. and Fox, Andrew and Beck-Johnson, Lindsay M. and Betancourt, Julio L. and Hooten, Mevin B. and Jarnevich, Catherine S. and Keitt, Timothy H. and Kenney, Melissa A. and Laney, Christine M. and Larsen, Laurel G. and Loescher, Henry W. and Lunch, Claire K. and Pijanowski, Bryan C. and Randerson, James T. and Read, Emily K. and Tredennick, Andrew T. and Vargas, Rodrigo and Weathers, Kathleen C. and White, Ethan P.},
doi = {10.1073/pnas.1710231115},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
pages = {201710231},
pmid = {29382745},
title = {{Iterative near-term ecological forecasting: Needs, opportunities, and challenges}},
year = {2018}
}


@article{Worm2006,
author = {Worm, Boris and Barbier, Edward B and Beaumont, Nicola and Duffy, J Emmett and Folke, Carl and Halpern, Benjamin S. and Jackson, Jeremy B C and Lotze, Heike K and Micheli, Fiorenza and Palumbi, Stephen R and Sala, Enric and Selkoe, Kimberley a and Stachowicz, John J and Watson, Reg},
doi = {10.1126/science.1132294},
issn = {1095-9203},
journal = {Science (New York, N.Y.)},
month = {nov},
number = {5800},
pages = {787--90},
pmid = {17082450},
title = {{Impacts of biodiversity loss on ocean ecosystem services.}},
volume = {314},
year = {2006}
}


@article{pomdp-intro,
	title = {Resolving the {Measurement} {Uncertainty} {Paradox} in {Ecological} {Management}},
	copyright = {All rights reserved},
	issn = {0003-0147, 1537-5323},
	url = {https://www.journals.uchicago.edu/doi/10.1086/702704},
	doi = {10.1086/702704},
	language = {en},
	urldate = {2019-04-07},
	journal = {The American Naturalist},
	author = {Memarzadeh, Milad and Boettiger, Carl},
	month = apr,
	year = {2019},
	pages = {000--000}
}


@article{Possingham2013,
	title = {Predicting species distributions for conservation decisions},
	volume = {16},
	issn = {1461-023X, 1461-0248},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/ele.12189},
	doi = {10.1111/ele.12189},
	language = {en},
	number = {12},
	urldate = {2021-05-07},
	journal = {Ecology Letters},
	author = {Guisan, Antoine and Tingley, Reid and Baumgartner, John B. and Naujokaitis‐Lewis, Ilona and Sutcliffe, Patricia R. and Tulloch, Ayesha I. T. and Regan, Tracey J. and Brotons, Lluis and McDonald‐Madden, Eve and Mantyka‐Pringle, Chrystal and Martin, Tara G. and Rhodes, Jonathan R. and Maggini, Ramona and Setterfield, Samantha A. and Elith, Jane and Schwartz, Mark W. and Wintle, Brendan A. and Broennimann, Olivier and Austin, Mike and Ferrier, Simon and Kearney, Michael R. and Possingham, Hugh P. and Buckley, Yvonne M.},
	editor = {Arita, Hector},
	month = dec,
	year = {2013},
	pages = {1424--1435},
	file = {Full Text:/home/cboettig/Zotero/storage/I4VERGLV/Guisan et al. - 2013 - Predicting species distributions for conservation .pdf:application/pdf}
}

@article{ppo,
	title = {Proximal {Policy} {Optimization} {Algorithms}},
	url = {http://arxiv.org/abs/1707.06347},
	urldate = {2020-04-25},
	journal = {arXiv:1707.06347 [cs]},
	author = {Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
	month = aug,
	year = {2017},
	note = {arXiv: 1707.06347},
	keywords = {Computer Science - Machine Learning},
}


@article{mbpo,
	title = {When to {Trust} {Your} {Model}: {Model}-{Based} {Policy} {Optimization}},
	shorttitle = {When to {Trust} {Your} {Model}},
	url = {http://arxiv.org/abs/1906.08253},
	urldate = {2021-05-04},
	journal = {arXiv:1906.08253 [cs, stat]},
	author = {Janner, Michael and Fu, Justin and Zhang, Marvin and Levine, Sergey},
	month = nov,
	year = {2019},
	note = {arXiv: 1906.08253},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: NeurIPS 2019. Code at https://github.com/JannerM/mbpo, project page at: https://people.eecs.berkeley.edu/{\textasciitilde}janner/mbpo/},
}

@article{a3c,
	title = {Reinforcement {Learning} through {Asynchronous} {Advantage} {Actor}-{Critic} on a {GPU}},
	url = {http://arxiv.org/abs/1611.06256},
	urldate = {2021-05-04},
	journal = {arXiv:1611.06256 [cs]},
	author = {Babaeizadeh, Mohammad and Frosio, Iuri and Tyree, Stephen and Clemons, Jason and Kautz, Jan},
	month = mar,
	year = {2017},
	note = {arXiv: 1611.06256},
	keywords = {Computer Science - Machine Learning},
}

@article{trpo,
	title = {Trust {Region} {Policy} {Optimization}},
	url = {http://arxiv.org/abs/1502.05477},
	urldate = {2021-05-04},
	journal = {arXiv:1502.05477 [cs]},
	author = {Schulman, John and Levine, Sergey and Moritz, Philipp and Jordan, Michael I. and Abbeel, Pieter},
	month = apr,
	year = {2017},
	note = {arXiv: 1502.05477},
	keywords = {Computer Science - Machine Learning},
	annote = {Comment: 16 pages, ICML 2015},
}

@article{apex,
	title = {Distributed {Prioritized} {Experience} {Replay}},
	url = {http://arxiv.org/abs/1803.00933},
	urldate = {2021-05-04},
	journal = {arXiv:1803.00933 [cs]},
	author = {Horgan, Dan and Quan, John and Budden, David and Barth-Maron, Gabriel and Hessel, Matteo and van Hasselt, Hado and Silver, David},
	month = mar,
	year = {2018},
	note = {arXiv: 1803.00933},
	keywords = {Computer Science - Machine Learning},
	annote = {Comment: Accepted to International Conference on Learning Representations 2018},
}


@article{impala,
	title = {{IMPALA}: {Scalable} {Distributed} {Deep}-{RL} with {Importance} {Weighted} {Actor}-{Learner} {Architectures}},
	shorttitle = {{IMPALA}},
	url = {http://arxiv.org/abs/1802.01561},
	urldate = {2021-05-04},
	journal = {arXiv:1802.01561 [cs]},
	author = {Espeholt, Lasse and Soyer, Hubert and Munos, Remi and Simonyan, Karen and Mnih, Volodymir and Ward, Tom and Doron, Yotam and Firoiu, Vlad and Harley, Tim and Dunning, Iain and Legg, Shane and Kavukcuoglu, Koray},
	month = jun,
	year = {2018},
	note = {arXiv: 1802.01561},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
}

@article{drlthatmatters,
	title = {Deep {Reinforcement} {Learning} that {Matters}},
	url = {http://arxiv.org/abs/1709.06560},
	urldate = {2021-05-04},
	journal = {arXiv:1709.06560 [cs, stat]},
	author = {Henderson, Peter and Islam, Riashat and Bachman, Philip and Pineau, Joelle and Precup, Doina and Meger, David},
	month = jan,
	year = {2019},
	note = {arXiv: 1709.06560},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: Accepted to the Thirthy-Second AAAI Conference On Artificial Intelligence (AAAI), 2018},
}

@article{rl_brain,
	title = {Reinforcement learning in the brain},
	volume = {53},
	issn = {00222496},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0022249608001181},
	doi = {10.1016/j.jmp.2008.12.005},
	language = {en},
	number = {3},
	urldate = {2021-05-17},
	journal = {Journal of Mathematical Psychology},
	author = {Niv, Yael},
	month = jun,
	year = {2009},
	pages = {139--154},
}

@book{suttonbarto,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT press},
}

@article{Possingham2006,
	title = {Prioritizing global conservation efforts},
	volume = {440},
	issn = {0028-0836, 1476-4687},
	url = {http://www.nature.com/articles/nature04366},
	doi = {10.1038/nature04366},
	language = {en},
	number = {7082},
	urldate = {2021-05-07},
	journal = {Nature},
	author = {Wilson, Kerrie A. and McBride, Marissa F. and Bode, Michael and Possingham, Hugh P.},
	month = mar,
	year = {2006},
	pages = {337--340}
}

@article{Possingham2009,
	title = {Optimal {Allocation} of {Resources} among {Threatened} {Species}: a {Project} {Prioritization} {Protocol}},
	volume = {23},
	issn = {08888892, 15231739},
	shorttitle = {Optimal {Allocation} of {Resources} among {Threatened} {Species}},
	url = {http://doi.wiley.com/10.1111/j.1523-1739.2008.01124.x},
	doi = {10.1111/j.1523-1739.2008.01124.x},
	language = {en},
	number = {2},
	urldate = {2021-05-07},
	journal = {Conservation Biology},
	author = {Joseph, Liana N. and Maloney, Richard F. and Possingham, Hugh P.},
	month = apr,
	year = {2009},
	pages = {328--338}
}

@article{Possingham2004,
	title = {Does conservation planning matter in a dynamic and uncertain world?},
	volume = {7},
	issn = {1461-023X, 1461-0248},
	url = {http://doi.wiley.com/10.1111/j.1461-0248.2004.00624.x},
	doi = {10.1111/j.1461-0248.2004.00624.x},
	language = {en},
	number = {8},
	urldate = {2021-05-07},
	journal = {Ecology Letters},
	author = {Meir, Eli and Andelman, Sandy and Possingham, Hugh P.},
	month = aug,
	year = {2004},
	pages = {615--622}
}

@article{Possignham2014,
	title = {Targeting {Global} {Protected} {Area} {Expansion} for {Imperiled} {Biodiversity}},
	volume = {12},
	issn = {1545-7885},
	url = {https://dx.plos.org/10.1371/journal.pbio.1001891},
	doi = {10.1371/journal.pbio.1001891},
	language = {en},
	number = {6},
	urldate = {2021-05-07},
	journal = {PLoS Biology},
	author = {Venter, Oscar and Fuller, Richard A. and Segan, Daniel B. and Carwardine, Josie and Brooks, Thomas and Butchart, Stuart H. M. and Di Marco, Moreno and Iwamura, Takuya and Joseph, Liana and O'Grady, Damien and Possingham, Hugh P. and Rondinini, Carlo and Smith, Robert J. and Venter, Michelle and Watson, James E. M.},
	editor = {Moritz, Craig},
	month = jun,
	year = {2014},
	pages = {e1001891},
	file = {Full Text:/home/cboettig/Zotero/storage/RHQ7T8S8/Venter et al. - 2014 - Targeting Global Protected Area Expansion for Impe.pdf:application/pdf}
}



@article{netflix_prize,
	title = {Innovation and learning performance implications of free revealing and knowledge brokering in competing communities: insights from the {Netflix} {Prize} challenge},
	volume = {19},
	issn = {1381-298X, 1572-9346},
	shorttitle = {Innovation and learning performance implications of free revealing and knowledge brokering in competing communities},
	url = {http://link.springer.com/10.1007/s10588-012-9137-7},
	doi = {10.1007/s10588-012-9137-7},
	language = {en},
	number = {1},
	urldate = {2021-05-11},
	journal = {Computational and Mathematical Organization Theory},
	author = {Villarroel, J. Andrei and Taylor, John E. and Tucci, Christopher L.},
	month = mar,
	year = {2013},
	pages = {42--77}
}


@article{gpu_computing,
	title = {Supercharge your data wrangling with a graphics card},
	volume = {562},
	issn = {0028-0836, 1476-4687},
	url = {http://www.nature.com/articles/d41586-018-06870-8},
	doi = {10.1038/d41586-018-06870-8},
	language = {en},
	number = {7725},
	urldate = {2021-05-11},
	journal = {Nature},
	author = {Matthews, David},
	month = oct,
	year = {2018},
	pages = {151--152},
	file = {Full Text:/home/cboettig/Zotero/storage/JC4ZJSS2/Matthews - 2018 - Supercharge your data wrangling with a graphics ca.pdf:application/pdf}
}

@article{qbias,
	title = {Maxmin {Q}-learning: {Controlling} the {Estimation} {Bias} of {Q}-learning},
	shorttitle = {Maxmin {Q}-learning},
	url = {http://arxiv.org/abs/2002.06487},
	urldate = {2021-05-17},
	journal = {arXiv:2002.06487 [cs]},
	author = {Lan, Qingfeng and Pan, Yangchen and Fyshe, Alona and White, Martha},
	month = feb,
	year = {2020},
	note = {arXiv: 2002.06487},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
}


@article{universalapproximators,
	title = {Multilayer feedforward networks are universal approximators},
	volume = {2},
	issn = {0893-6080},
	url = {https://www.sciencedirect.com/science/article/pii/0893608089900208},
	doi = {10.1016/0893-6080(89)90020-8},
	language = {en},
	number = {5},
	urldate = {2021-05-17},
	journal = {Neural Networks},
	author = {Hornik, Kurt and Stinchcombe, Maxwell and White, Halbert},
	month = jan,
	year = {1989},
	keywords = {Back-propagation networks, Feedforward networks, Mapping networks, Network representation capability, Sigma-Pi networks, Squashing functions, Stone-Weierstrass Theorem, Universal approximation},
	pages = {359--366},
}

@InProceedings{grande14,
  title = 	 {Sample Efficient Reinforcement Learning with Gaussian Processes},
  author = 	 {Robert Grande and Thomas Walsh and Jonathan How},
  booktitle = 	 {Proceedings of the 31st International Conference on Machine Learning},
  pages = 	 {1332--1340},
  year = 	 {2014},
  editor = 	 {Eric P. Xing and Tony Jebara},
  volume = 	 {32},
  number =       {2},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Bejing, China},
  month = 	 {22--24 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v32/grande14.pdf},
  url = 	 {http://proceedings.mlr.press/v32/grande14.html},
}

@article{briefsurveydrl,
	title = {A {Brief} {Survey} of {Deep} {Reinforcement} {Learning}},
	volume = {34},
	issn = {1053-5888},
	url = {http://arxiv.org/abs/1708.05866},
	doi = {10.1109/MSP.2017.2743240},
	number = {6},
	urldate = {2021-05-17},
	journal = {IEEE Signal Processing Magazine},
	author = {Arulkumaran, Kai and Deisenroth, Marc Peter and Brundage, Miles and Bharath, Anil Anthony},
	month = nov,
	year = {2017},
	note = {arXiv: 1708.05866},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
	pages = {26--38},
}

@article{lecun_deep_2015,
	title = {Deep learning},
	volume = {521},
	issn = {0028-0836, 1476-4687},
	url = {http://www.nature.com/articles/nature14539},
	doi = {10.1038/nature14539},
	language = {en},
	number = {7553},
	urldate = {2021-05-17},
	journal = {Nature},
	author = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
	month = may,
	year = {2015},
	pages = {436--444},
}

@article{berger-tal_exploration-exploitation_2014,
	title = {The {Exploration}-{Exploitation} {Dilemma}: {A} {Multidisciplinary} {Framework}},
	volume = {9},
	issn = {1932-6203},
	shorttitle = {The {Exploration}-{Exploitation} {Dilemma}},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0095693},
	doi = {10.1371/journal.pone.0095693},
	language = {en},
	number = {4},
	urldate = {2021-05-17},
	journal = {PLOS ONE},
	author = {Berger-Tal, Oded and Nathan, Jonathan and Meron, Ehud and Saltz, David},
	month = apr,
	year = {2014},
	note = {Publisher: Public Library of Science},
	keywords = {Animal behavior, Behavior, Decision making, Foraging, Human learning, Learning, Machine learning, Machine learning algorithms},
	pages = {e95693},
}

@article{gu_q-prop_2017,
	title = {Q-{Prop}: {Sample}-{Efficient} {Policy} {Gradient} with {An} {Off}-{Policy} {Critic}},
	shorttitle = {Q-{Prop}},
	url = {http://arxiv.org/abs/1611.02247},
	urldate = {2021-05-17},
	journal = {arXiv:1611.02247 [cs]},
	author = {Gu, Shixiang and Lillicrap, Timothy and Ghahramani, Zoubin and Turner, Richard E. and Levine, Sergey},
	month = feb,
	year = {2017},
	note = {arXiv: 1611.02247},
	keywords = {Computer Science - Machine Learning},
}

@article{van_hasselt_deep_2015,
	title = {Deep {Reinforcement} {Learning} with {Double} {Q}-learning},
	url = {http://arxiv.org/abs/1509.06461},
	urldate = {2021-05-18},
	journal = {arXiv:1509.06461 [cs]},
	author = {van Hasselt, Hado and Guez, Arthur and Silver, David},
	month = dec,
	year = {2015},
	note = {arXiv: 1509.06461},
	keywords = {Computer Science - Machine Learning},
}


@article{wang_sample_2017,
	title = {Sample {Efficient} {Actor}-{Critic} with {Experience} {Replay}},
	url = {http://arxiv.org/abs/1611.01224},
	urldate = {2021-05-18},
	journal = {arXiv:1611.01224 [cs]},
	author = {Wang, Ziyu and Bapst, Victor and Heess, Nicolas and Mnih, Volodymyr and Munos, Remi and Kavukcuoglu, Koray and de Freitas, Nando},
	month = jul,
	year = {2017},
	note = {arXiv: 1611.01224},
	keywords = {Computer Science - Machine Learning},
}


@article{scoville2021,
  title={Algorithmic conservation in a changing climate},
  author={Scoville, Caleb and Chapman, Melissa and Amironesei, Razvan and Boettiger, Carl},
  journal={Current Opinion in Environmental Sustainability},
  volume={51},
  pages={30--35},
  year={2021},
  publisher={Elsevier}
}

@article{vinuesa2020,
  title={The role of artificial intelligence in achieving the Sustainable Development Goals},
  author={Vinuesa, Ricardo and Azizpour, Hossein and Leite, Iolanda and Balaam, Madeline and Dignum, Virginia and Domisch, Sami and Fell{\"a}nder, Anna and Langhans, Simone Daniela and Tegmark, Max and Nerini, Francesco Fuso},
  journal={Nature communications},
  volume={11},
  number={1},
  pages={1--10},
  year={2020},
  publisher={Nature Publishing Group}
}

@article{mcdonald2021,
  title={Satellites can reveal global extent of forced labor in the world’s fishing fleet},
  author={McDonald, Gavin G and Costello, Christopher and Bone, Jennifer and Cabral, Reniel B and Farabee, Valerie and Hochberg, Timothy and Kroodsma, David and Mangin, Tracey and Meng, Kyle C and Zahn, Oliver},
  journal={Proceedings of the National Academy of Sciences},
  volume={118},
  number={3},
  year={2021},
  publisher={National Acad Sciences}
}

@article{adams2019,
  title={Geographies of conservation II: Technology, surveillance and conservation by algorithm},
  author={Adams, William M},
  journal={Progress in Human Geography},
  volume={43},
  number={2},
  pages={337--350},
  year={2019},
  publisher={SAGE Publications Sage UK: London, England}
}

@article{wearn2019,
  title={Responsible AI for conservation},
  author={Wearn, Oliver R and Freeman, Robin and Jacoby, David MP},
  journal={Nature Machine Intelligence},
  volume={1},
  number={2},
  pages={72--73},
  year={2019},
  publisher={Nature Publishing Group}
}

@article{kalluri2020,
  title={Don't ask if artificial intelligence is good or fair, ask how it shifts power.},
  author={Kalluri, Pratyusha},
  journal={Nature},
  volume={583},
  number={7815},
  pages={169--169},
  year={2020}
}

@article{vinuesa2020,
  title={The role of artificial intelligence in achieving the Sustainable Development Goals},
  author={Vinuesa, Ricardo and Azizpour, Hossein and Leite, Iolanda and Balaam, Madeline and Dignum, Virginia and Domisch, Sami and Fell{\"a}nder, Anna and Langhans, Simone Daniela and Tegmark, Max and Nerini, Francesco Fuso},
  journal={Nature communications},
  volume={11},
  number={1},
  pages={1--10},
  year={2020},
  publisher={Nature Publishing Group}
}

@article{swartz2021,
  title={AIS-based profiling of fishing vessels falls short as a “proof of concept” for identifying forced labor at sea},
  author={Swartz, Wilf and Cisneros-Montemayor, Andr{\'e}s M and Singh, Gerald G and Boutet, Patrick and Ota, Yoshitaka},
  journal={Proceedings of the National Academy of Sciences},
  volume={118},
  number={19},
  year={2021},
  publisher={National Acad Sciences}
}


@article{dice,
	title = {An {Optimal} {Transition} {Path} for {Controlling} {Greenhouse} {Gases}},
	volume = {258},
	issn = {0036-8075, 1095-9203},
	url = {https://www.sciencemag.org/lookup/doi/10.1126/science.258.5086.1315},
	doi = {10.1126/science.258.5086.1315},
	language = {en},
	number = {5086},
	urldate = {2021-05-24},
	journal = {Science},
	author = {Nordhaus, W. D.},
	month = nov,
	year = {1992},
	pages = {1315--1319}
}



@article{Reed1979,
author = {Reed, William J},
doi = {10.1016/0095-0696(79)90014-7},
issn = {00950696},
journal = {Journal of Environmental Economics and Management},
month = {dec},
number = {4},
pages = {350--363},
publisher = {Elsevier},
title = {{Optimal escapement levels in stochastic and deterministic harvesting models}},
volume = {6},
year = {1979}
}


@article{Schaefer1954,
author = {Schaefer, Milner B.},
doi = {10.1007/BF02464432},
issn = {0092-8240},
journal = {Bulletin of the Inter-American Tropical Tuna Commission},
month = {mar},
number = {2},
pages = {27--56},
title = {{Some aspects of the dynamics of populations important to the management of the commercial marine fisheries}},
volume = {1},
year = {1954}
}


@article{Ludwig1982,
	title = {Optimal harvesting with imprecise parameter estimates},
	volume = {14},
	issn = {03043800},
	doi = {10.1016/0304-3800(82)90023-0},
	number = {3-4},
	journal = {Ecological Modelling},
	author = {Ludwig, Donald and Walters, Carl J},
	month = jan,
	year = {1982},
	keywords = {parameter uncertainty},
	pages = {273--292}
}

@article{May1977,
	title = {Thresholds and breakpoints in ecosystems with a multiplicity of stable states},
	volume = {269},
	issn = {0028-0836},
	url = {http://www.nature.com/doifinder/10.1038/269471a0},
	doi = {10.1038/269471a0},
	number = {5628},
	journal = {Nature},
	author = {May, Robert M},
	month = oct,
	year = {1977},
	pages = {471--477}
}

@article{Polasky2011,
author = {Polasky, Stephen and Carpenter, Stephen R. and Folke, Carl and Keeler, Bonnie},
doi = {10.1016/j.tree.2011.04.007},
issn = {01695347},
journal = {Trends in Ecology {\&} Evolution},
month = {aug},
number = {8},
pages = {398--404},
pmid = {21616553},
publisher = {Elsevier Ltd},
title = {{Decision-making under great uncertainty: environmental management in an era of global change}},
volume = {26},
year = {2011}
}
@article{Walters1981,
	title = {Optimum {Escapements} in the {Face} of {Alternative} {Recruitment} {Hypotheses}},
	volume = {38},
	issn = {0706-652X, 1205-7533},
	url = {http://www.nrcresearchpress.com/doi/10.1139/f81-091},
	doi = {10.1139/f81-091},
	language = {en},
	number = {6},
	urldate = {2021-02-04},
	journal = {Canadian Journal of Fisheries and Aquatic Sciences},
	author = {Walters, Carl J.},
	month = jun,
	year = {1981},
	pages = {678--689}
}


@book{Clark1990,
author = {Clark, Colin W},
isbn = {0471508837},
pages = {400},
publisher = {Wiley-Interscience},
title = {{Mathematical Bioeconomics: The Optimal Management of Renewable Resources, 2nd Edition}},
year = {1990}
}

@article{Clark1973,
author = { Colin W. Clark },
title = {Profit Maximization and the Extinction of Animal Species},
journal = {Journal of Political Economy},
volume = {81},
number = {4},
pages = {950-961},
year = {1973},
doi = {10.1086/260090},
}


@article{Marescot2013,
	title = {Complex decisions made simple: a primer on stochastic dynamic programming},
	volume = {4},
	url = {http://doi.wiley.com/10.1111/2041-210X.12082},
	doi = {10.1111/2041-210X.12082},
	number = {9},
	journal = {Methods in Ecology and Evolution},
	author = {Marescot, Lucile and Chapron, Guillaume and Chadès, Iadine and Fackler, Paul L. and Duchamp, Christophe and Marboutin, Eric and Gimenez, Olivier},
	year = {2013},
	pages = {872--884}
}


@article{Dai2012,
	title = {Generic {Indicators} for {Loss} of {Resilience} {Before} a {Tipping} {Point} {Leading} to {Population} {Collapse}},
	volume = {336},
	issn = {0036-8075},
	url = {http://www.sciencemag.org/cgi/doi/10.1126/science.1219805},
	doi = {10.1126/science.1219805},
	number = {6085},
	journal = {Science (New York, N.Y.)},
	author = {Dai, Lei and Vorselen, Daan and Korolev, Kirill S and Gore, J.},
	month = may,
	year = {2012},
	pages = {1175--1177}
}

@article{Carpenter2011,
	title = {Early {Warnings} of {Regime} {Shifts}: {A} {Whole}-{Ecosystem} {Experiment}},
	volume = {1079},
	issn = {0036-8075},
	url = {dx.doi.org/10.1126/science.1203672},
	doi = {10.1126/science.1203672},
	journal = {Science (New York, N.Y.)},
	author = {Carpenter, Stephen R and Cole, J. J. and Pace, Michael L and Batt, Ryan D. and Brock, William A and Cline, Timothy J. and Coloso, J. and Hodgson, J. R. and Kitchell, J F and Seekell, David A and Smith, L. and Weidel, B.},
	month = apr,
	year = {2011}
}

@article{Barnosky2012,
	title = {Approaching a state shift in {Earth}’s biosphere},
	volume = {486},
	issn = {0028-0836, 1476-4687},
	url = {http://www.nature.com/articles/nature11018},
	doi = {10.1038/nature11018},
	language = {en},
	number = {7401},
	urldate = {2021-05-24},
	journal = {Nature},
	author = {Barnosky, Anthony D. and Hadly, Elizabeth A. and Bascompte, Jordi and Berlow, Eric L. and Brown, James H. and Fortelius, Mikael and Getz, Wayne M. and Harte, John and Hastings, Alan and Marquet, Pablo A. and Martinez, Neo D. and Mooers, Arne and Roopnarine, Peter and Vermeij, Geerat and Williams, John W. and Gillespie, Rosemary and Kitzes, Justin and Marshall, Charles and Matzke, Nicholas and Mindell, David P. and Revilla, Eloy and Smith, Adam B.},
	month = jun,
	year = {2012},
	pages = {52--58}
}


@article{Worm2006,
author = {Worm, Boris and Barbier, Edward B and Beaumont, Nicola and Duffy, J Emmett and Folke, Carl and Halpern, Benjamin S and Jackson, Jeremy B C and Lotze, Heike K and Micheli, Fiorenza and Palumbi, Stephen R and Sala, Enric and Selkoe, Kimberley a and Stachowicz, John J and Watson, Reg},
doi = {10.1126/science.1132294},
journal = {Science (New York, N.Y.)},
month = {nov},
number = {5800},
pages = {787--90},
pmid = {17082450},
title = {{Impacts of biodiversity loss on ocean ecosystem services.}},
url = {doi.org/10.1126/science.1132294},
volume = {314},
year = {2006}
}
@article{Worm2009,
author = {Worm, Boris and Hilborn, Ray and Baum, Julia K and Branch, Trevor A and Collie, Jeremy S and Costello, Christopher and Fogarty, Michael J and Fulton, Elizabeth a and Hutchings, Jeffrey a and Jennings, Simon and Jensen, Olaf P and Lotze, Heike K and Mace, Pamela M and McClanahan, Tim R and Minto, C{\'{o}}il{\'{i}}n and Palumbi, Stephen R and Parma, Ana M and Ricard, Daniel and Rosenberg, Andrew a and Watson, Reg and Zeller, Dirk},
doi = {10.1126/science.1173146},
journal = {Science (New York, N.Y.)},
month = {jul},
number = {5940},
pages = {578--85},
pmid = {19644114},
title = {{Rebuilding global fisheries.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19644114},
volume = {325},
year = {2009}
}

@article{pomdp-intro,
author = {Memarzadeh, Milad and Boettiger, Carl},
title = {Resolving the Measurement Uncertainty Paradox in Ecological Management},
journal = {The American Naturalist},
volume = {193},
number = {5},
pages = {645-660},
year = {2019},
doi = {10.1086/702704}
}

@article {Memarzadeh2019,
	author = {Memarzadeh, Milad and Britten, Gregory L. and Worm, Boris and Boettiger, Carl},
	title = {Rebuilding global fisheries under uncertainty},
	volume = {116},
	number = {32},
	pages = {15985--15990},
	year = {2019},
	doi = {10.1073/pnas.1902657116},
	publisher = {National Academy of Sciences},
	issn = {0027-8424},
	URL = {https://www.pnas.org/content/116/32/15985},
	eprint = {https://www.pnas.org/content/116/32/15985.full.pdf},
	journal = {Proceedings of the National Academy of Sciences}
}

@article{Costello2016,
author = {Costello, Christopher and Ovando, Daniel and Clavelle, Tyler and Strauss, C. Kent and Hilborn, Ray and Melnychuk, Michael C. and Branch, Trevor A and Gaines, Steven D and Szuwalski, Cody S. and Cabral, Reniel B. and Rader, Douglas N. and Leland, Amanda},
doi = {10.1073/pnas.1520420113},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
month = {may},
number = {18},
pages = {5125--5129},
title = {{Global fishery prospects under contrasting management regimes}},
volume = {113},
year = {2016}
}

@article{Walters1978,
	title = {Ecological {Optimization} and {Adaptive} {Management}},
	volume = {9},
	issn = {0066-4162},
	doi = {10.1146/annurev.es.09.110178.001105},
	number = {1},
	journal = {Annual Review of Ecology and Systematics},
	author = {Walters, Carl J and Hilborn, Ray},
	month = nov,
	year = {1978},
	keywords = {parameter uncertainty},
	pages = {157--188}
}

@article{Fischer2009,
	title = {Integrating resilience thinking and optimisation for conservation.},
	volume = {24},
	issn = {0169-5347},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/19665820},
	doi = {10.1016/j.tree.2009.03.020},
	number = {10},
	journal = {Trends in ecology \& evolution},
	author = {Fischer, Joern and Peterson, Garry D and Gardner, Toby A. and Gordon, Line J and Fazey, Ioan and Elmqvist, Thomas and Felton, Adam and Folke, Carl and Dovers, Stephen},
	month = oct,
	year = {2009},
	pmid = {19665820},
	pages = {549--54}
}


@book{Hastings2012,
	address = {Oakland, CA},
	title = {Encyclopedia of {Theoretical} {Ecology}},
	isbn = {978-0-520-26965-1},
	publisher = {University of California Press},
	editor = {Hastings, Alan and Gross, Louis J.},
	year = {2012}
}



@article{sortie,
	title = {Forest {Models} {Defined} by {Field} {Measurements}: {Estimation}, {Error} {Analysis} and {Dynamics}},
	volume = {66},
	issn = {00129615},
	shorttitle = {Forest {Models} {Defined} by {Field} {Measurements}},
	url = {http://doi.wiley.com/10.2307/2963479},
	doi = {10.2307/2963479},
	language = {en},
	number = {1},
	urldate = {2021-05-24},
	journal = {Ecological Monographs},
	author = {Pacala, Stephen W. and Canham, Charles D. and Saponara, John and Silander, John A. and Kobe, Richard K. and Ribbens, Eric},
	month = feb,
	year = {1996},
	pages = {1--43}
}

@article{ecopath,
	title = {Ecopath with {Ecosim} as a model-building toolbox: {Source} code capabilities, extensions, and variations},
	volume = {319},
	issn = {03043800},
	shorttitle = {Ecopath with {Ecosim} as a model-building toolbox},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S030438001500280X},
	doi = {10.1016/j.ecolmodel.2015.06.031},
	language = {en},
	urldate = {2021-05-24},
	journal = {Ecological Modelling},
	author = {Steenbeek, Jeroen and Buszowski, Joe and Christensen, Villy and Akoglu, Ekin and Aydin, Kerim and Ellis, Nick and Felinto, Dalai and Guitton, Jerome and Lucey, Sean and Kearney, Kelly and Mackinson, Steven and Pan, Mike and Platts, Mark and Walters, Carl},
	month = jan,
	year = {2016},
	pages = {178--189}
}

@inproceedings{imagenet,
	address = {Miami, FL},
	title = {{ImageNet}: {A} large-scale hierarchical image database},
	isbn = {978-1-4244-3992-8},
	shorttitle = {{ImageNet}},
	url = {https://ieeexplore.ieee.org/document/5206848/},
	doi = {10.1109/CVPR.2009.5206848},
	urldate = {2021-05-24},
	booktitle = {2009 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
	publisher = {IEEE},
	author = {Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and {Kai Li} and {Li Fei-Fei}},
	month = jun,
	year = {2009},
	pages = {248--255}
}

@article{salimans_evolution_2017,
	title = {Evolution {Strategies} as a {Scalable} {Alternative} to {Reinforcement} {Learning}},
	url = {http://arxiv.org/abs/1703.03864},
	urldate = {2021-05-19},
	journal = {arXiv:1703.03864 [cs, stat]},
	author = {Salimans, Tim and Ho, Jonathan and Chen, Xi and Sidor, Szymon and Sutskever, Ilya},
	month = sep,
	year = {2017},
	note = {arXiv: 1703.03864},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning},
}

@article{plappert_parameter_2018,
	title = {Parameter {Space} {Noise} for {Exploration}},
	url = {http://arxiv.org/abs/1706.01905},
	urldate = {2021-06-01},
	journal = {arXiv:1706.01905 [cs, stat]},
	author = {Plappert, Matthias and Houthooft, Rein and Dhariwal, Prafulla and Sidor, Szymon and Chen, Richard Y. and Chen, Xi and Asfour, Tamim and Abbeel, Pieter and Andrychowicz, Marcin},
	month = jan,
	year = {2018},
	note = {arXiv: 1706.01905},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Computer Science - Robotics, Statistics - Machine Learning},
}

@article{go-explore,
	title = {Go-{Explore}: a {New} {Approach} for {Hard}-{Exploration} {Problems}},
	shorttitle = {Go-{Explore}},
	url = {http://arxiv.org/abs/1901.10995},
	urldate = {2021-06-01},
	journal = {arXiv:1901.10995 [cs, stat]},
	author = {Ecoffet, Adrien and Huizinga, Joost and Lehman, Joel and Stanley, Kenneth O. and Clune, Jeff},
	month = feb,
	year = {2021},
	note = {arXiv: 1901.10995},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{ruder_overview_2017,
	title = {An overview of gradient descent optimization algorithms},
	url = {http://arxiv.org/abs/1609.04747},
	urldate = {2021-05-19},
	journal = {arXiv:1609.04747 [cs]},
	author = {Ruder, Sebastian},
	month = jun,
	year = {2017},
	note = {arXiv: 1609.04747},
	keywords = {Computer Science - Machine Learning},
}

@article{Qproof,
	title = {Convergence of {Q}-learning: a simple proof},
	language = {en},
	author = {Melo, Francisco S},
	pages = {4},
}

@article{schulman_high-dimensional_2018,
	title = {High-{Dimensional} {Continuous} {Control} {Using} {Generalized} {Advantage} {Estimation}},
	url = {http://arxiv.org/abs/1506.02438},
	urldate = {2021-06-01},
	journal = {arXiv:1506.02438 [cs]},
	author = {Schulman, John and Moritz, Philipp and Levine, Sergey and Jordan, Michael and Abbeel, Pieter},
	month = oct,
	year = {2018},
	note = {arXiv: 1506.02438},
	keywords = {Computer Science - Machine Learning, Computer Science - Robotics, Electrical Engineering and Systems Science - Systems and Control},
}

@article{gsde,
	title = {Generalized {State}-{Dependent} {Exploration} for {Deep} {Reinforcement} {Learning} in {Robotics}},
	url = {http://arxiv.org/abs/2005.05719},
	urldate = {2021-06-01},
	journal = {arXiv:2005.05719 [cs, stat]},
	author = {Raffin, Antonin and Stulp, Freek},
	month = may,
	year = {2020},
	note = {arXiv: 2005.05719},
	keywords = {Computer Science - Machine Learning, Computer Science - Robotics, Statistics - Machine Learning},
}

@article{ahmed_understanding_2019,
	title = {Understanding the impact of entropy on policy optimization},
	url = {http://arxiv.org/abs/1811.11214},
	urldate = {2021-06-01},
	journal = {arXiv:1811.11214 [cs, stat]},
	author = {Ahmed, Zafarali and Roux, Nicolas Le and Norouzi, Mohammad and Schuurmans, Dale},
	month = jun,
	year = {2019},
	note = {arXiv: 1811.11214},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}


@article{schaul_prioritized_2016,
	title = {Prioritized {Experience} {Replay}},
	url = {http://arxiv.org/abs/1511.05952},
	urldate = {2021-06-01},
	journal = {arXiv:1511.05952 [cs]},
	author = {Schaul, Tom and Quan, John and Antonoglou, Ioannis and Silver, David},
	month = feb,
	year = {2016},
	note = {arXiv: 1511.05952},
	keywords = {Computer Science - Machine Learning},
}

@article{teh_distral_2017,
	title = {Distral: {Robust} {Multitask} {Reinforcement} {Learning}},
	shorttitle = {Distral},
	url = {http://arxiv.org/abs/1707.04175},
	urldate = {2021-05-27},
	journal = {arXiv:1707.04175 [cs, stat]},
	author = {Teh, Yee Whye and Bapst, Victor and Czarnecki, Wojciech Marian and Quan, John and Kirkpatrick, James and Hadsell, Raia and Heess, Nicolas and Pascanu, Razvan},
	month = jul,
	year = {2017},
	note = {arXiv: 1707.04175},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@InProceedings{pmlr-v97-cobbe19a,
  title = 	 {Quantifying Generalization in Reinforcement Learning},
  author =       {Cobbe, Karl and Klimov, Oleg and Hesse, Chris and Kim, Taehoon and Schulman, John},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {1282--1289},
  year = 	 {2019},
  editor = 	 {Kamalika Chaudhuri and Ruslan Salakhutdinov},
  volume = 	 {97},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--15 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v97/cobbe19a/cobbe19a.pdf},
  url = 	 {
http://proceedings.mlr.press/v97/cobbe19a.html
},
}

@article{cogswell_reducing_2016,
	title = {Reducing {Overfitting} in {Deep} {Networks} by {Decorrelating} {Representations}},
	url = {http://arxiv.org/abs/1511.06068},
	urldate = {2021-05-27},
	journal = {arXiv:1511.06068 [cs, stat]},
	author = {Cogswell, Michael and Ahmed, Faruk and Girshick, Ross and Zitnick, Larry and Batra, Dhruv},
	month = jun,
	year = {2016},
	note = {arXiv: 1511.06068},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{heuillet_explainability_2021,
	title = {Explainability in deep reinforcement learning},
	volume = {214},
	issn = {0950-7051},
	url = {https://www.sciencedirect.com/science/article/pii/S0950705120308145},
	doi = {10.1016/j.knosys.2020.106685},
	language = {en},
	urldate = {2021-05-27},
	journal = {Knowledge-Based Systems},
	author = {Heuillet, Alexandre and Couthouis, Fabien and Díaz-Rodríguez, Natalia},
	month = feb,
	year = {2021},
	keywords = {Deep Learning, Explainable artificial intelligence, Machine Learning, Reinforcement Learning, Representation learning, Responsible artificial intelligence},
	pages = {106685},
}


@article{castelvecchi_can_2016,
	title = {Can we open the black box of {AI}?},
	volume = {538},
	url = {http://www.nature.com/news/can-we-open-the-black-box-of-ai-1.20731},
	doi = {10.1038/538020a},
	abstract = {Artificial intelligence is everywhere. But before scientists trust it, they first need to understand how machines learn.},
	language = {en},
	number = {7623},
	urldate = {2021-05-27},
	journal = {Nature News},
	author = {Castelvecchi, Davide},
	month = oct,
	year = {2016},
	note = {Section: News Feature},
	pages = {20},
}


@article{hadfield-menell_inverse_2020,
	title = {Inverse {Reward} {Design}},
	url = {http://arxiv.org/abs/1711.02827},
	urldate = {2021-05-27},
	journal = {arXiv:1711.02827 [cs]},
	author = {Hadfield-Menell, Dylan and Milli, Smitha and Abbeel, Pieter and Russell, Stuart and Dragan, Anca},
	month = oct,
	year = {2020},
	note = {arXiv: 1711.02827},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
}

@inproceedings{reward_shaping,
  author = {Grzeundefined, Marek},
  title = {Reward Shaping in Episodic Reinforcement Learning},
  year = {2017},
  publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
  address = {Richland, SC},
  pages = {565–573},
  numpages = {9},
  keywords = {reinforcement learning, reward structures for learning, reward shaping, multiagent learning, potential-based reward shaping},
  location = {S\~{a}o Paulo, Brazil},
  series = {AAMAS '17}
}

@article{bellemare2016,
	title = {Unifying {Count}-{Based} {Exploration} and {Intrinsic} {Motivation}},
	url = {http://arxiv.org/abs/1606.01868},
	urldate = {2021-06-05},
	journal = {arXiv:1606.01868 [cs, stat]},
	author = {Bellemare, Marc G. and Srinivasan, Sriram and Ostrovski, Georg and Schaul, Tom and Saxton, David and Munos, Remi},
	month = nov,
	year = {2016},
	note = {arXiv: 1606.01868},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{largescalecuriosity,
	title = {Large-{Scale} {Study} of {Curiosity}-{Driven} {Learning}},
	url = {http://arxiv.org/abs/1808.04355},
	urldate = {2021-06-05},
	journal = {arXiv:1808.04355 [cs, stat]},
	author = {Burda, Yuri and Edwards, Harri and Pathak, Deepak and Storkey, Amos and Darrell, Trevor and Efros, Alexei A.},
	month = aug,
	year = {2018},
	note = {arXiv: 1808.04355},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Robotics, Statistics - Machine Learning},
}

@article{nevergiveup,
	title = {Never {Give} {Up}: {Learning} {Directed} {Exploration} {Strategies}},
	shorttitle = {Never {Give} {Up}},
	url = {http://arxiv.org/abs/2002.06038},
	urldate = {2021-06-05},
	journal = {arXiv:2002.06038 [cs, stat]},
	author = {Badia, Adrià Puigdomènech and Sprechmann, Pablo and Vitvitskyi, Alex and Guo, Daniel and Piot, Bilal and Kapturowski, Steven and Tieleman, Olivier and Arjovsky, Martín and Pritzel, Alexander and Bolt, Andew and Blundell, Charles},
	month = feb,
	year = {2020},
	note = {arXiv: 2002.06038},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{instability_2019,
	title = {Deterministic {Implementations} for {Reproducibility} in {Deep} {Reinforcement} {Learning}},
	url = {http://arxiv.org/abs/1809.05676},
	abstract = {While deep reinforcement learning (DRL) has led to numerous successes in recent years, reproducing these successes can be extremely challenging. One reproducibility challenge particularly relevant to DRL is nondeterminism in the training process, which can substantially affect the results. Motivated by this challenge, we study the positive impacts of deterministic implementations in eliminating nondeterminism in training. To do so, we consider the particular case of the deep Q-learning algorithm, for which we produce a deterministic implementation by identifying and controlling all sources of nondeterminism in the training process. One by one, we then allow individual sources of nondeterminism to affect our otherwise deterministic implementation, and measure the impact of each source on the variance in performance. We find that individual sources of nondeterminism can substantially impact the performance of agent, illustrating the benefits of deterministic implementations. In addition, we also discuss the important role of deterministic implementations in achieving exact replicability of results.},
	urldate = {2021-06-07},
	journal = {arXiv:1809.05676 [cs]},
	author = {Nagarajan, Prabhat and Warnell, Garrett and Stone, Peter},
	month = jun,
	year = {2019},
	note = {arXiv: 1809.05676},
	keywords = {Computer Science - Artificial Intelligence},
	annote = {Comment: 17 Pages}
}
