


```{r knitr, include = FALSE}
knitr::opts_chunk$set(echo=TRUE, message = FALSE, warning = FALSE,
                      fig.width = 7, fig.height = 4, cache = TRUE)
ggplot2::theme_set(ggplot2::theme_bw())

scale_colour_discrete <- function(...) ggthemes::scale_colour_solarized()
scale_fill_discrete <- function(...) ggthemes::scale_fill_solarized()
pal <- ggthemes::solarized_pal()(8)
txtcolor <- "#586e75"
```

```{r setup, cache = FALSE, message=FALSE}
# R dependencies
library(tidyverse)
library(patchwork)
library(reticulate)

## Python dependencies loaded via R
sb3         <- import ("stable_baselines3")
gym         <- import ("gym")
gym_fishing <- import("gym_fishing")
```


```{r}
library(contentid)
ramzip <- resolve("hash://md5/fac27d8b7876df29afaeadcd7f5a3b77")
unzip(ramzip, exdir = "ramlegacy")
load("ramlegacy/RAMLDB v4.491/DB Files With Assessment Data/R Data/DBdata[asmt][v4.491].RData")
```


```{r}
ramlegacy <- 
  timeseries_values_views %>%
  select(stockid, stocklong, year, SSB, TC) %>%
  left_join(stock) %>%
  left_join(area) %>%
  select(stockid, scientificname, 
         commonname, areaname, country, year, 
         SSB, TC) %>%
  left_join(timeseries_units_views %>%
              rename(TC_units = TC, SSB_units = SSB)) %>%
  select(scientificname, commonname, 
         stockid, areaname, country, year, 
         SSB, TC, SSB_units, TC_units)
```


Let's filter out missing data, non-matching units, and obvious reporting errors (catch exceeding total spawning biomass), then we re-scale each series into the 0,1 by appropriate choice of units:

```{r}
stock_ids <- c("PLAICNS", "ARGHAKENARG")

fish <- ramlegacy %>% 
  filter(stockid %in% stock_ids) %>% 
  filter(!is.na(SSB), !is.na(TC)) %>%
  filter(SSB_units == "MT", TC_units=="MT") %>% 
  filter(SSB > TC) %>%
  select(-SSB_units, -TC_units) %>% 
  group_by(stockid) %>%
  mutate(scaled_catch = TC / max(SSB),
         scaled_biomass = SSB / max(SSB)) 

hake <- fish  %>% filter(commonname=="Argentine hake")
write_csv(hake, "../data/hake.csv")
```




```{r}
# Simulate management under the trained agent
env <- gym$make("fishing-v1", r = 1.0379274,	K = 1.197693, sigma = 0.1121662)
td3 <- sb3$TD3$load("cache/td3")

```



```{r}
hake <- read_csv("../data/hake.csv")
x0 <- hake %>%
 filter(year == min(year)) %>%
  pull(scaled_biomass)
Tmax <- 15
years <-1986:2000

td3_state <- td3_action <- numeric(Tmax)
td3_state[1] <- x0
td3_action[1] <- NA
## represent the initial state size in the 'rescaled' state space.
state <- env$get_state( x0 )
```

```{r}

for(i in 2:Tmax){
  
  # RL-recommended harvest action:
  out <- td3$predict(state)
  action <- out[[1]]
  
  # Record state and resulting action
  td3_state[i] <- env$get_fish_population(state)
  td3_action[i] <- env$get_quota(action)
  
  # Implement RL-recommended harvest:
  result <- env$step(action)
  state <- result[[1]]

}

df <- bind_rows(
  tibble(year = years, state = td3_state, action = td3_action, model = "TD3"),
  tibble(year = years, state = hake$scaled_biomass, action = hake$scaled_catch, model = "historical"))

df %>% ggplot(aes(year, state, col=model)) + geom_line() + geom_point(aes(year, action, col=model))

```











```{r subset}
examples <- df2 %>% 
  ungroup() %>% 
  group_by(commonname)
```



```{r}
## Model does not estimate sigma_m; data is insufficient to do so.
gs_code  <- nimble::nimbleCode({
  r ~ dunif(0, 2)
  K ~ dunif(0, 2)
  sigma ~ dunif(0, 1)
  
  x[1] <- x0
  for(t in 1:(N-1)){
    mu[t] <- x[t] + x[t] * r * (1 - x[t] / K) - min(a[t],x[t])
    x[t+1] ~ dnorm(mu[t], sd = sigma)
  }
})
fit_models <- function(fish, code){
  # fish <- examples %>% filter(stockid == stock_ids[1])
  
  ## Rescale data
  N <- dim(fish)[1]
  scaled_data <- data.frame(t = 1:N, 
                            y = fish$scaled_biomass, 
                            a = fish$scaled_catch)
  data = data.frame(x = scaled_data$y)
  ## Compile  model
  constants <- list(N = N, a = scaled_data$a)
  inits <- list(r = 0.5, K = 0.5, sigma = 0.02, x0 = scaled_data$y[1])
  model <- nimbleModel(code, constants, data, inits)
  C_model <- compileNimble(model)
  
  mcmcspec <- configureMCMC(model, thin = 1e2)
  mcmc <- buildMCMC(mcmcspec)
  Cmcmc <- compileNimble(mcmc, project = model)
  Cmcmc$run(1e6)
  
  
  samples <- as.data.frame(as.matrix(Cmcmc$mvSamples))
  burnin <- 1:(0.05 * dim(samples)[1]) # drop first 5%
  samples <- samples[-burnin,1:(length(inits) - 1)] # drop raised vars, burnin
  #gather(samples) %>% ggplot() + geom_density(aes(value)) + facet_wrap(~key, scale='free')
   
  ## Return fit
  data.frame(stockid = fish$stockid[1],
             commonname = fish$commonname[1],
             r = mean(samples$r),
             K = mean(samples$K),
             sigma_g = mean(samples$sigma),
             r_sd = sd(samples$r),
             K_sd = sd(samples$K),
             sigma_g_sd = sd(samples$sigma),
             stringsAsFactors = FALSE)
  
}
```



```{r}
set.seed(123)
fits <- examples %>% do(fit_models(., code=gs_code))
fits 
```



```{r}
pars <- fits %>% ungroup() %>% select(commonname, r, K, sigma_g) 
pars
```