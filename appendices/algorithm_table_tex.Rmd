---
output: 
  pdf_document:
    fig_width: 7
    fig_height: 6.5
    fig_crop: False
  
header-includes:
  - \RequirePackage{colortbl}
  - \RequirePackage{xcolor}
  - \usepackage{xcolor}[tbl]
  - \pagestyle{empty}
  - \geometry{margin=0in}

bibliography: ../manuscript/references.bib

---
\definecolor{lightgray}{gray}{0.9}
\begin{center}
\begin{tabular}{c|c|c|c|c}
\hline
Algorithm & Description                                     & Model       & Policy     & Method \\
\hline
\rowcolor{lightgray}
MBPO      & Model-based Policy Optimization \cite{mbpo}    & Model-based & On-policy  & Policy Gradient \\
MCTS      & Monte Carlo Tree Search \cite{suttonbarto}     & Model-based & Either     & Any\\
\rowcolor{lightgray}
A2C       & Advantage Actor Critic  \cite{A2C}             & Model-free  & On-policy  & Actor-critic\\
A3C       & Asynchronous A2C  \cite{a3c}                   & Model-free  & On-policy  & Actor-critic\\
\rowcolor{lightgray}
TRPO      & Trust Region Policy Optimization  \cite{trpo}  & Model-free  & On-policy  & Policy Gradient\\
PPO       & Proximal Policy Optimization  \cite{ppo}       & Model-free  & On-policy  & Actor-critic\\
\rowcolor{lightgray}
DQN       & Deep Q Networks  \cite{DQN}                    & Model-free  & Off-policy & Value-Based\\
DDPG      & Deep Deterministic Policy Gradient  \cite{ddpg}& Model-free  & Off-policy & Actor-critic\\
\rowcolor{lightgray}
TD3       & Twin Delayed DDPG  \cite{TD3}                  & Model-free  & Off-policy & Actor-critic\\
SAC       & Soft Actor Critic  \cite{sac}                  & Model-free  & Off-policy & Actor-critic\\
\rowcolor{lightgray}
IMPALA    & Importance Weighted Actor Learner \cite{impala}& Model-free  & Off-policy & Actor-critic\\
\end{tabular}
\end{center}
